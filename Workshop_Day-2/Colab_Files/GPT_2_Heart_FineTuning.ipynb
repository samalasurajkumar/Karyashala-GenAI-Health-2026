{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxLrmnv6zhad",
        "outputId": "64e7807a-4e8d-4c8e-9801-46c7bc9504de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.10.0\n",
            "numpy version: 2.0.2\n",
            "tiktoken version: 0.12.0\n",
            "torch version: 2.10.0+cu128\n",
            "tensorflow version: 2.19.0\n",
            "pandas version: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version, PackageNotFoundError\n",
        "\n",
        "pkgs = [\n",
        "    \"matplotlib\",\n",
        "    \"numpy\",\n",
        "    \"tiktoken\",\n",
        "    \"torch\",\n",
        "    \"tensorflow\",\n",
        "    \"pandas\"\n",
        "]\n",
        "\n",
        "for p in pkgs:\n",
        "    try:\n",
        "        print(f\"{p} version: {version(p)}\")\n",
        "    except PackageNotFoundError:\n",
        "        print(f\"{p} NOT INSTALLED\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oVCd7qozs8N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QOvqDWgWzxfW",
        "outputId": "801bf5c3-3747-4b57-f686-539d15d8020d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0        0  A 59-year-old male patient with non-anginal pa...\n",
              "1        0  A 30-year-old female patient with typical angi...\n",
              "2        0  A 57-year-old female patient with typical angi...\n",
              "3        0  A 48-year-old male patient with atypical angin...\n",
              "4        0  A 47-year-old male patient with asymptomatic c...\n",
              "..     ...                                                ...\n",
              "815      1  A 58-year-old male patient with non-anginal pa...\n",
              "816      1  A 46-year-old male patient with asymptomatic c...\n",
              "817      1  A 63-year-old male patient with asymptomatic c...\n",
              "818      1  A 54-year-old male patient with asymptomatic c...\n",
              "819      1  A 69-year-old male patient with asymptomatic c...\n",
              "\n",
              "[820 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f854c9d-ddff-4769-9af6-c1d06ca14661\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A 59-year-old male patient with non-anginal pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A 30-year-old female patient with typical angi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A 57-year-old female patient with typical angi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A 48-year-old male patient with atypical angin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A 47-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>1</td>\n",
              "      <td>A 58-year-old male patient with non-anginal pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>1</td>\n",
              "      <td>A 46-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>1</td>\n",
              "      <td>A 63-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>1</td>\n",
              "      <td>A 54-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>819</th>\n",
              "      <td>1</td>\n",
              "      <td>A 69-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>820 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f854c9d-ddff-4769-9af6-c1d06ca14661')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f854c9d-ddff-4769-9af6-c1d06ca14661 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f854c9d-ddff-4769-9af6-c1d06ca14661');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_7d77d2b0-5000-4045-8674-e1579498bcd6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7d77d2b0-5000-4045-8674-e1579498bcd6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 820,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 820,\n        \"samples\": [\n          \"A 36-year-old male patient with atypical angina, resting blood pressure 120 mmHg, cholesterol level 267 mg/dL, normal fasting blood sugar, normal ECG result, maximum heart rate 160, no exercise-induced angina, ST depression 3.0, and flat ST segment.\",\n          \"A 52-year-old male patient with typical angina, resting blood pressure 118 mmHg, cholesterol level 186 mg/dL, normal fasting blood sugar, left ventricular hypertrophy, maximum heart rate 190, no exercise-induced angina, ST depression 0.0, and flat ST segment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_id = \"1DPjhMRXwbefS0ll0trUfvfeSR_mDv_iL\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df.head()\n",
        "\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vf_AYToz7zS",
        "outputId": "b6597960-4935-4b37-a4a2-d5484e88bcc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "0    410\n",
            "1    410\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "SLlquNlnz-3W",
        "outputId": "08cb159f-026a-473d-b817-5731977b6661"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0        0  A 59-year-old male patient with non-anginal pa...\n",
              "1        0  A 30-year-old female patient with typical angi...\n",
              "2        0  A 57-year-old female patient with typical angi...\n",
              "3        0  A 48-year-old male patient with atypical angin...\n",
              "4        0  A 47-year-old male patient with asymptomatic c...\n",
              "..     ...                                                ...\n",
              "815      1  A 58-year-old male patient with non-anginal pa...\n",
              "816      1  A 46-year-old male patient with asymptomatic c...\n",
              "817      1  A 63-year-old male patient with asymptomatic c...\n",
              "818      1  A 54-year-old male patient with asymptomatic c...\n",
              "819      1  A 69-year-old male patient with asymptomatic c...\n",
              "\n",
              "[820 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-708cec41-9a0a-4c15-b067-d110ee0f6ce1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A 59-year-old male patient with non-anginal pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A 30-year-old female patient with typical angi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A 57-year-old female patient with typical angi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A 48-year-old male patient with atypical angin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A 47-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>1</td>\n",
              "      <td>A 58-year-old male patient with non-anginal pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>1</td>\n",
              "      <td>A 46-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>1</td>\n",
              "      <td>A 63-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>1</td>\n",
              "      <td>A 54-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>819</th>\n",
              "      <td>1</td>\n",
              "      <td>A 69-year-old male patient with asymptomatic c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>820 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-708cec41-9a0a-4c15-b067-d110ee0f6ce1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-708cec41-9a0a-4c15-b067-d110ee0f6ce1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-708cec41-9a0a-4c15-b067-d110ee0f6ce1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_61a5c200-d0f1-4c37-8577-7362f61f885c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('balanced_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_61a5c200-d0f1-4c37-8577-7362f61f885c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('balanced_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_df",
              "summary": "{\n  \"name\": \"balanced_df\",\n  \"rows\": 820,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 820,\n        \"samples\": [\n          \"A 36-year-old male patient with atypical angina, resting blood pressure 120 mmHg, cholesterol level 267 mg/dL, normal fasting blood sugar, normal ECG result, maximum heart rate 160, no exercise-induced angina, ST depression 3.0, and flat ST segment.\",\n          \"A 52-year-old male patient with typical angina, resting blood pressure 118 mmHg, cholesterol level 186 mg/dL, normal fasting blood sugar, left ventricular hypertrophy, maximum heart rate 190, no exercise-induced angina, ST depression 0.0, and flat ST segment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "balanced_df = df[[\"Label\", \"Text\"]]\n",
        "balanced_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE-6BVZJ0BuK",
        "outputId": "aea6fb90-3e69-4671-96b8-211137473ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train distribution:\n",
            "Label\n",
            "0    287\n",
            "1    287\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Validation distribution:\n",
            "Label\n",
            "0    41\n",
            "1    41\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test distribution:\n",
            "Label\n",
            "1    82\n",
            "0    82\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Files saved successfully:\n",
            "train.csv\n",
            "validation.csv\n",
            "test.csv\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Train (70%) and Temp (30%)\n",
        "train_df, temp_df = train_test_split(\n",
        "    balanced_df,\n",
        "    test_size=0.3,\n",
        "    random_state=123,\n",
        "    stratify=balanced_df[\"Label\"]\n",
        ")\n",
        "\n",
        "# Step 2: Validation (10%) and Test (20%)\n",
        "validation_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=2/3,   # 0.2 / 0.3 = 2/3\n",
        "    random_state=123,\n",
        "    stratify=temp_df[\"Label\"]\n",
        ")\n",
        "\n",
        "# Step 3: Check distributions\n",
        "print(\"Train distribution:\")\n",
        "print(train_df[\"Label\"].value_counts())\n",
        "\n",
        "print(\"\\nValidation distribution:\")\n",
        "print(validation_df[\"Label\"].value_counts())\n",
        "\n",
        "print(\"\\nTest distribution:\")\n",
        "print(test_df[\"Label\"].value_counts())\n",
        "\n",
        "# Step 4: Save to CSV\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "validation_df.to_csv(\"validation.csv\", index=False)\n",
        "test_df.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "print(\"\\nFiles saved successfully:\")\n",
        "print(\"train.csv\")\n",
        "print(\"validation.csv\")\n",
        "print(\"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PKFtJJH0JkU",
        "outputId": "1e09fe84-c4b0-455b-83b5-0df6ce19477a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amfubnXA0Mle"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class HeartDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfdTNCDQ0QYo",
        "outputId": "f2dd2b05-4133-4af7-cd56-d6c9dd93459f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n"
          ]
        }
      ],
      "source": [
        "train_dataset = HeartDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoCdrRtd0S8P"
      },
      "outputs": [],
      "source": [
        "val_dataset = HeartDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = HeartDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrmvN_IR0eef"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SrGLAiy0g7R",
        "outputId": "971d0b4e-3070-41bf-d31d-3c84fbb8c3e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([8, 69])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lgEW1zf0jG7",
        "outputId": "d0ea1d9a-6d25-4d27-dc9f-583c3e098bff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 training batches\n",
            "11 validation batches\n",
            "21 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a58xC0NS0lGI"
      },
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12}\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdoL5jpg0vUf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyUZEu9H0x7o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = x @ self.W_key\n",
        "        queries = x @ self.W_query\n",
        "        values = x @ self.W_value\n",
        "\n",
        "        attn_scores = queries @ keys.T # omega\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "class SelfAttention_v2(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        attn_scores = queries @ keys.T\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "class CausalAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, context_length,\n",
        "                 dropout, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.d_out = d_out\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.dropout = nn.Dropout(dropout)  # New\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(1, 2)\n",
        "        attn_scores.masked_fill_(\n",
        "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "        attn_weights = self.dropout(attn_weights)  # New\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(\n",
        "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
        "             for _ in range(num_heads)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "class PyTorchMultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, num_heads, dropout=0.0, qkv_bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_out % num_heads == 0, \"d_out is indivisible by num_heads\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.d_out = d_out\n",
        "\n",
        "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
        "        self.proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_tokens, embed_dim = x.shape\n",
        "\n",
        "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
        "        qkv = self.qkv(x)\n",
        "\n",
        "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
        "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
        "\n",
        "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "\n",
        "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
        "        queries, keys, values = qkv\n",
        "\n",
        "        use_dropout = 0. if not self.training else self.dropout\n",
        "\n",
        "        context_vec = nn.functional.scaled_dot_product_attention(\n",
        "            queries, keys, values, attn_mask=None, dropout_p=use_dropout, is_causal=True)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
        "\n",
        "        context_vec = self.proj(context_vec)\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E3spEUz003P"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "######################\n",
        "# Bonus\n",
        "######################\n",
        "\n",
        "\n",
        "class FeedForwardFast(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            nn.GELU(approximate=\"tanh\"),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlockFast(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = PyTorchMultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForwardFast(cfg)\n",
        "        self.norm1 = nn.LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = nn.LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModelFast(nn.Module):\n",
        "    \"\"\"\n",
        "    A faster variant of GPTModel optimized for training speed.\n",
        "\n",
        "    This version is only marginally faster on CPU (~1.02x) but significantly\n",
        "    faster on GPU (~2.05x) during training, thanks to optimized CUDA kernels\n",
        "    and FlashAttention support.\n",
        "\n",
        "    Key differences from the original GPTModel:\n",
        "    1. Uses PyTorch's built-in LayerNorm instead of a custom implementation.\n",
        "    2. Uses PyTorch's built-in GELU instead of a custom implementation.\n",
        "    3. Uses PyTorch's scaled_dot_product_attention instead of a custom MultiHeadAttention.\n",
        "    4. Automatically enables FlashAttention on compatible GPUs.\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlockFast(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = nn.LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGZqApFE1H27"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import requests\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # subtract rowwise max before softmax\n",
        "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path, backup_url)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "\n",
        "def download_file(url, destination, backup_url=None):\n",
        "    def _attempt_download(download_url):\n",
        "        response = requests.get(download_url, stream=True, timeout=60)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "        # Check if file exists and has same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size and file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return True\n",
        "\n",
        "        block_size = 1024  # 1 KB\n",
        "        desc = os.path.basename(download_url)\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=desc) as progress_bar:\n",
        "            with open(destination, \"wb\") as file:\n",
        "                for chunk in response.iter_content(chunk_size=block_size):\n",
        "                    if chunk:\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        if _attempt_download(url):\n",
        "            return\n",
        "    except requests.exceptions.RequestException:\n",
        "        if backup_url is not None:\n",
        "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
        "            try:\n",
        "                if _attempt_download(backup_url):\n",
        "                    return\n",
        "            except requests.exceptions.RequestException:\n",
        "                pass\n",
        "\n",
        "        error_message = (\n",
        "            f\"Failed to download from both primary URL ({url})\"\n",
        "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
        "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
        "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
        "        )\n",
        "        print(error_message)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkdaiE6g1LJg",
        "outputId": "640f5e8e-cc1b-41ce-9a38-ade5cccb68d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 135kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.05MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 150kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:30<00:00, 16.4MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 8.70MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.56MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.80MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeWUZLV51z-g",
        "outputId": "68718b9b-c474-44ad-b214-922b996c8ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Generative AI workshop, and my name is Bhupendra Kumar.  I am a software engineer and I am a member of the AI community.  \n"
          ]
        }
      ],
      "source": [
        "text_1 = \"Welcome to the Generative AI workshop, and my name is Bhupendra Kumar. \"\n",
        "\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=18,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht_5nIem12sR",
        "outputId": "24f12b67-11fe-49c8-93ca-21774941e7cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does the following patient have heart disease? Answer with 'yes' or 'no': 'A 48-year-old female patient with asymptomatic chest condition, resting blood pressure 138 mmHg, cholesterol level 214 mg/dL, normal fasting blood sugar, normal ECG result, maximum heart rate 108, exercise-induced angina, ST depression 1.5, and flat ST segment.'\n",
            "\n",
            "The study was funded by the National Heart, Lung, and Blood Institute of the National Institutes\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Does the following patient have heart disease? \"\n",
        "    \"Answer with 'yes' or 'no': \"\n",
        "    \"'A 48-year-old female patient with asymptomatic chest condition, \"\n",
        "    \"resting blood pressure 138 mmHg, cholesterol level 214 mg/dL, \"\n",
        "    \"normal fasting blood sugar, normal ECG result, maximum heart rate 108, \"\n",
        "    \"exercise-induced angina, ST depression 1.5, and flat ST segment.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=20,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIrlOZ6v1_PH",
        "outputId": "328f491b-5c00-4a08-fc52-960826371a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W_-gHDF2CnL"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe0StkrC2FAx"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeGCO6sB2HOw"
      },
      "outputs": [],
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myadajAq2JZ4",
        "outputId": "1824e436-2b12-49eb-e5dc-877a192d0b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR1chPqK2Lz3",
        "outputId": "d5917a9c-08f4-44a8-c71a-dfe0c44831b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwUlcXb-2P5A",
        "outputId": "94298f58-76ac-41ce-9611-1b89af50d451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h0K-P2c2SQT",
        "outputId": "4ae37465-37d4-48e3-9a17-12ac37b8ef59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ],
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "label = torch.argmax(probas)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cRr9zMD2UY4",
        "outputId": "6a526ceb-f522-4be6-f1af-265d0ff0c6b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ],
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRMKowCd2WoJ"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg4-9Ix02ZRW",
        "outputId": "76a4ec5d-500d-44cb-988e-8c5ff6c91a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Training accuracy: 52.50%\n",
            "Validation accuracy: 50.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    # Use PyTorch 2.9 or newer for stable mps results\n",
        "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
        "    if (major, minor) >= (2, 9):\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUVhhIrd2cjk"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8C4xkWK2e72"
      },
      "outputs": [],
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6zHIzLF2iIE",
        "outputId": "e401d3ed-5941-4d84-d7d7-7e94b88b7258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.378\n",
            "Validation loss: 2.036\n",
            "Test loss: 2.253\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmCIqFNJ2kvb"
      },
      "outputs": [],
      "source": [
        "# Overall the same as `train_model_simple`\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWrutHEB2nO4"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9KkH7r92qGm",
        "outputId": "396a6450-e328-4f38-894b-3672771d2190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.434, Val loss 1.972\n",
            "Ep 1 (Step 000050): Train loss 0.679, Val loss 0.704\n",
            "Training accuracy: 60.00% | Validation accuracy: 62.50%\n",
            "Ep 2 (Step 000100): Train loss 0.653, Val loss 0.658\n",
            "Training accuracy: 80.00% | Validation accuracy: 77.50%\n",
            "Ep 3 (Step 000150): Train loss 0.562, Val loss 0.579\n",
            "Ep 3 (Step 000200): Train loss 0.479, Val loss 0.497\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Ep 4 (Step 000250): Train loss 0.456, Val loss 0.498\n",
            "Training accuracy: 60.00% | Validation accuracy: 80.00%\n",
            "Ep 5 (Step 000300): Train loss 0.451, Val loss 0.483\n",
            "Ep 5 (Step 000350): Train loss 0.416, Val loss 0.475\n",
            "Training accuracy: 75.00% | Validation accuracy: 80.00%\n",
            "Ep 6 (Step 000400): Train loss 0.579, Val loss 0.466\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Ep 7 (Step 000450): Train loss 0.494, Val loss 0.440\n",
            "Training accuracy: 75.00% | Validation accuracy: 85.00%\n",
            "Ep 8 (Step 000500): Train loss 0.349, Val loss 0.432\n",
            "Ep 8 (Step 000550): Train loss 0.258, Val loss 0.431\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 9 (Step 000600): Train loss 0.299, Val loss 0.428\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Ep 10 (Step 000650): Train loss 0.420, Val loss 0.464\n",
            "Ep 10 (Step 000700): Train loss 0.406, Val loss 0.418\n",
            "Training accuracy: 82.50% | Validation accuracy: 82.50%\n",
            "Ep 11 (Step 000750): Train loss 0.499, Val loss 0.413\n",
            "Training accuracy: 85.00% | Validation accuracy: 82.50%\n",
            "Ep 12 (Step 000800): Train loss 0.440, Val loss 0.414\n",
            "Ep 12 (Step 000850): Train loss 0.427, Val loss 0.430\n",
            "Training accuracy: 82.50% | Validation accuracy: 87.50%\n",
            "Ep 13 (Step 000900): Train loss 0.236, Val loss 0.407\n",
            "Training accuracy: 80.00% | Validation accuracy: 87.50%\n",
            "Ep 14 (Step 000950): Train loss 0.285, Val loss 0.411\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Ep 15 (Step 001000): Train loss 0.247, Val loss 0.412\n",
            "Ep 15 (Step 001050): Train loss 0.230, Val loss 0.410\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Training completed in 1.12 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=0.001)\n",
        "\n",
        "num_epochs = 15\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM6QQ9Fl28o4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "xDw0qFtU3AWz",
        "outputId": "6d0a0cc0-e33b-41e1-fd69-1faeb2de6c68"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "mGLWOk3_3E6V",
        "outputId": "866b874f-6331-43e7-e97b-94c9f9e0ed30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soidupFk3HuI",
        "outputId": "b527fd90-9b19-4c07-85b2-d28bfe9f3a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 85.39%\n",
            "Validation accuracy: 82.93%\n",
            "Test accuracy: 84.15%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rkrLSqI3MwX"
      },
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "    assert max_length is not None, (\n",
        "        \"max_length must be specified. If you want to use the full model context, \"\n",
        "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
        "    )\n",
        "    assert max_length <= supported_context_length, (\n",
        "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
        "    )\n",
        "    # Alternatively, a more robust version is the following one, which handles the max_length=None case better\n",
        "    # max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
        "    # input_ids = input_ids[:max_len]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"Heart Disease\" if predicted_label == 1 else \"Normal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZmbC43M3PZI",
        "outputId": "08f7112d-018b-4c4a-8844-463d5b631324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heart Disease\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\n",
        "    \"A 61-year-old male patient with typical angina, \"\n",
        "    \"resting blood pressure 134 mmHg, \"\n",
        "    \"cholesterol level 234 mg/dL, \"\n",
        "    \"normal fasting blood sugar, \"\n",
        "    \"normal ECG result, \"\n",
        "    \"maximum heart rate 145, \"\n",
        "    \"no exercise-induced angina, \"\n",
        "    \"ST depression 2.6, \"\n",
        "    \"and flat ST segment.\"\n",
        ")\n",
        "\n",
        "prediction = classify_review(\n",
        "    text_1,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    device,\n",
        "    max_length=train_dataset.max_length\n",
        ")\n",
        "\n",
        "print(prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB1YyYTV3PVs",
        "outputId": "677294bf-7b99-4cb6-9e01-81bb366556ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"A 64-year-old female patient with asymptomatic chest condition, \"\n",
        "    \"resting blood pressure 180 mmHg, \"\n",
        "    \"cholesterol level 325 mg/dL, \"\n",
        "    \"normal fasting blood sugar, \"\n",
        "    \"normal ECG result, \"\n",
        "    \"maximum heart rate 154, \"\n",
        "    \"exercise-induced angina, \"\n",
        "    \"ST depression 0.0, \"\n",
        "    \"and upsloping ST segment.\"\n",
        ")\n",
        "prediction = classify_review(\n",
        "    text_2,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    device,\n",
        "    max_length=train_dataset.max_length\n",
        ")\n",
        "\n",
        "print(prediction)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}